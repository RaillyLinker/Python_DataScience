import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from scipy import stats

"""
[기본 통계]
- 데이터 분석에 필요한 기본적인 통계학에 대한 정리입니다.

[용어 정리]
(기본 용어)
- 모집단(Population) :
    자료를 추출할 관심의 대상으로 모든 가능한 추출값들의 집합입니다.
    모집단의 수가 적다면 관측자는 모든 데이터에 대한 관측이 가능하지만,
    모집단의 수가 너무 많다면 몇몇 데이터를 추려내야만 합니다.

- 표본(Sample) :
    모집단의 수가 너무 많을 때, 모집단을 대표할 수 있도록 일부만을 추출한 집합입니다.

- 모수(Parameter) :
    모집단의 분포의 특징을 나타내는 값으로, 평균, 분산, 표준편차 등이 있습니다.

- 통계량(Statistics) :
    추출한 데이터를 가지고 계산한 값으로, 종류에 따라 모수를 추정하는데 쓰입니다.
    표본평균, 표본분산, 표본표준편차 등이 있습니다.

- 평균(Mean) : 
    표본 N개의 데이터의 값을 모두 더한 후 N개로 나눈 값입니다.
    통계에서 중요한 값이므로 굳이 설명합니다.

- 중앙값(Median) :
    N개의 표본을 데이터 값으로 정렬했을 때, 그 중앙에 위치한 값입니다.
    만약 표본 N 이 짝수라면 중앙에 있는 2개의 값을 더한 후 2로 나눈 값을 사용합니다.

- 최빈값(Mode) :
    자료중 등장 빈도가 가장 많은 값입니다.

- 자유도 (Degrees of Freedom): 
    자유도란, 변화할 가능성입니다.
    예를들어 1 부터 N 까지 숫자가 적힌 제비뽑기를 할 때,
    N-1 번째로 제비를 뽑은 순간, 마지막 숫자인 N번째 뽑는 제비의 값은 기존에 나온 값들로 인하여 결정되버리죠.
    고로 이때의 자유도는 N-1 이 됩니다.

- 분산(Variance) :
    데이터가 전체적으로 평균을 중심으로하여 어느정도 흩어져있는지를 나타내는 지표입니다.
    N 개의 데이터에서 각 데이터에서 평균을 빼고 제곱을 한 결과값들을 모두 더하여 N으로 나눕니다.
    모수에 대한 분산이 아닌 표본에 대한 표본 분산의 경우는 N으로 나누는 것이 아닌 N-1 로 나누어줍니다.

    N-1 로 나누어주는 이유는 보다 자세한 수학적 증명은 따로 찾아보시고, 
    여기서는 그냥 편향 보정 (Bias Correction) 때문이라 생각하세요.
    
    표본의 분산을 단순히 n으로 나누면, 표본분산의 기대값이 실제 모집단 분산보다 작아지는 경향이 있습니다. 
    이는 표본이 모집단의 변동성을 완전히 대표하지 못하기 때문입니다. 
    따라서 n 대신 n−1로 나누어 불편추정량을 얻습니다. 
    이렇게 하면 표본분산의 기대값이 모집단 분산과 같아집니다.

- 표준편차(Standard Deviation) :
    분산 값에 루트를 씌운 값입니다.
    분산의 계산식에는 제곱이 들어가므로 값이 지나치게 커질 수 있는데, 이를 억제하는 효과가 있습니다.

- 사분위수(Quartile) :
    사분위수(四分位數, quartile)는 데이터 집합을 네 개의 동일한 부분으로 나누는 세 점을 나타내는 통계적 개념입니다. 
    사분위수는 데이터의 분포를 이해하고, 데이터의 중앙 경향성과 변동성을 설명하는 데 사용됩니다. 
    
    사분위수에는 네 가지 주요 지표가 있습니다:
        제1사분위수 (Q1): 
            데이터의 하위 25% 지점을 나타냅니다. 
            데이터를 오름차순으로 정렬했을 때 전체 데이터의 25%가 이 값보다 작고, 나머지 75%가 이 값보다 큽니다. 
            1사분위수는 전체 데이터의 4분의 1 위치에 해당합니다.
        
        제2사분위수 (Q2) 또는 중앙값 (Median): 
            데이터의 중앙을 나타냅니다. 전체 데이터의 50%가 이 값보다 작고, 나머지 50%가 이 값보다 큽니다. 
            이는 데이터 집합의 중앙값과 동일합니다.
        
        제3사분위수 (Q3): 
            데이터의 상위 25% 지점을 나타냅니다. 
            전체 데이터의 75%가 이 값보다 작고, 나머지 25%가 이 값보다 큽니다. 
            3사분위수는 전체 데이터의 4분의 3 위치에 해당합니다.
        
        사분위범위 (Interquartile Range, IQR): 
            제3사분위수(Q3)와 제1사분위수(Q1)의 차이를 말합니다. 
            IQR은 데이터의 중간 50%의 범위를 나타내며, 데이터의 산포도를 측정하는 데 사용됩니다. 
            IQR은 이상치(outlier)를 탐지하는 데 유용합니다.
            이상치에 대한 상하한을 구하여 이 값의 범위를 넘어서는 값을 이상치로 규정하는 것인데,
            하한 값: Q1 - 1.5 * IQR
            상한 값: Q3 + 1.5 * IQR
            위와 같이 IQR 을 기준으로 상하한값을 설정하는 것입니다.
    
    사분위수는 데이터의 분포를 시각적으로 이해하는 데 중요한 도구로, 상자 그림(box plot)과 같은 그래프에서 자주 사용됩니다. 
    예를 들어, 상자 그림에서 상자는 제1사분위수와 제3사분위수 사이를 나타내며, 중앙선은 중앙값을 표시합니다.
    
    사분위수를 계산하는 과정은 다음과 같습니다:
    
    데이터를 오름차순으로 정렬합니다.
    전체 데이터의 개수를 4로 나누어 각 사분위수의 위치를 결정합니다.
    위치에 따라 데이터를 나누어 각 사분위수 값을 찾습니다.

- 표준 정규 분포(Standard Normal Distribution) :
    표준 정규 분포는 평균이 0이고, 표준 편차가 1인 정규 분포를 말합니다. 
    정규 분포는 통계학에서 매우 중요한 분포로, 데이터가 평균을 중심으로 대칭적으로 분포하고, 
    중앙에 데이터가 밀집되어 있으며, 평균에서 멀어질수록 데이터의 빈도가 감소하는 특징을 가지고 있습니다.
    

(기술 통계학 (Descriptive Statistics))
- 수집한 자료의 정리, 표현, 요약, 해석 등을 통해 자료의 특성을 규명하는 통계적 방법

- 통계는 평균과 분산의 마술이라고 표현하시는 분이 계신데,
    그 말대로 통계에서 중요한 것은 데이터가 무슨 값을 중심으로하며, 중심에서 얼마나 퍼져있는지를 확인하는 것이 중요하다고 합니다.

    중심 경향성(Central Tendency) 의 측도는 평균, 중앙값, 최빈값을 보면 되며,
    산포도(Dispersion) 의 측도는 범위, 분산, 표준편차 를 보는 것으로,
    
    데이터에서 위와같은 정보를 얻어내는 것을 기본으로 하여 기술 통계가 시작됩니다.


(통계적 추론(Statistical Inference))
- 표본으로부터의 정보를 이용하여 모집단에 관한 추측이나 결론을 이끌어내는 과정을 통계적 추론이라고 합니다.

- 통계적 추론에서 결론의 신빙성은 표본의 크기에 따라 달라지고, 확률을 통해 수 값으로 나타납니다.

- 통계적 추론은 크게 추정(Extimation)과 유의성 검정(Significance test), 또는 가설 검정(Hypothesis test) 으로 나뉩니다.


(통계의 맹점)
- 수집된 표본에 대해서는 언제나 정리, 표현, 요약, 해석 등을 할 수 있으나,
    이를 모집단 전체에 대해 일반화 하거나 이를 기반으로 정보를 고유할 때에는 항상 주의를 요해야만 한다고 합니다.
    수집되지 않고 관측되지 않은 데이터가 존재할 가능성은 언제나 존재하기 때문이죠.
    통계적 발언은 진실보다야 불확실하지만 아무 근거 없는 주장보다는 단연 설득력을 갖추기에 좋은 도구를 다루듯 잘 다루는 것이 좋을 것입니다.


(자료의 종류)
- 연속형 자료 : 자료의 값이 연속적인 어떤 구간에서 관측되는 자료
    기온, 전등의 지속시간 등이 이에 속합니다.

- 이산형 자료 :
    이산형 자료는 보험 가입건수, 차량 생산 대수 같이 수를 세아리는 계수형(Counting) 자료와,
    성별, 인종, 나이대 같이 특정 기준으로 묶는 범주형(Categorical) 자료가 있습니다.

- 자료의 형태에 따라서 유용한 데이터 시각화 방식이 다릅니다.
    연속형 자료의 경우는 히스토그램, 상자 그래프 등이 좋고,
    이산형 자료의 경우에는 도수 분포표, 막대그래프, 원그래프 등이 유용합니다.
"""

"""
(이산형 자료 기본 시각화 기법)
- 도수 분포표(Frequency Table) :
    자료가 가질수 있는 값을 어떤 특성에 의하여 구분하여 해당 특성을 갖는 자료의 개수(도수, Frequency)를 표로 나타낸 것입니다.

- 막대 그래프 :
    수평축에 특성값을 놓고, 막대의 높이가 도수나 상대도수에 비례하게 그린 것입니다.

- 원 그래프 :
    중심각의 크기나 넓이가 상대도수에 비례하도록 그린 것입니다.

- 아래의 예제 코드는, 주사위를 1000 번 던졌을 때 나타나는 1 에서 6 사이의 값에 대한 도수를 시각화 한 것입니다.
"""


def discrete_data_sample():
    # 데이터 생성
    data = np.random.randint(1, 7, size=1000)  # 1부터 6 사이의 정수 1000개 생성

    # 데이터프레임 생성
    df = pd.DataFrame(data, columns=['Value'])

    # 도수 분포표 생성
    frequency_table = df['Value'].value_counts().sort_index()

    # 도수 분포표 출력
    print("도수 분포표:")
    print(frequency_table)

    # 도수 분포표를 막대 그래프로 시각화
    plt.figure(figsize=(10, 6))
    sns.barplot(x=frequency_table.index, y=frequency_table.values, color='skyblue')
    plt.title('Frequency Distribution of Values')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.show()

    # 도수 분포표를 원 그래프로 시각화
    plt.figure(figsize=(10, 10))
    plt.pie(frequency_table.values, labels=frequency_table.index, autopct='%1.1f%%', startangle=140,
            colors=sns.color_palette('pastel'))
    plt.title('Frequency Distribution of Values (Pie Chart)')
    plt.axis('equal')  # 원형을 유지하기 위해 축을 'equal'로 설정
    plt.show()


"""
(연속형 자료 기본 시각화 기법)
- 히스토그램(Histogram) : 
    계급 구간을 나누어 그 위에 넓이가 상대 도수 또는 도수에 비례하도록 직사각형을 그린 그림입니다.
    일반적으로 전체 직사각형들의 넓이의 합을 1로 하며,
    계급을 나누는 방식, 폭의 너비에 따라 모양이 변할 수 있습니다.

- 박스 그림(Box Plot)
    박스 플롯(Box Plot)은 데이터 분포의 요약 통계량을 시각적으로 나타내는 도구입니다. 
    주로 데이터의 중앙값, 사분위수, 그리고 이상치(outliers)를 파악하는 데 유용합니다.
    해석법을 설명하자면,
    상자의 가운데 선은 중앙값이고,
    상자의 시작부분은 1분위수, 끝 부분은 3분위수입니다.
    확장된 선의 끝은 IQR 을 기준으로 이상치 한계선을 나타내는 것으로,
    이 선을 넘어서는 값은 이상치입니다.
"""


def continuous_data_sample():
    # 데이터 생성
    np.random.seed(42)  # 재현성을 위해 시드 설정
    data = np.random.normal(loc=50, scale=15, size=1000)  # 평균 50, 표준편차 15의 정규분포를 따르는 1000개의 데이터 생성

    # 데이터프레임 생성
    df = pd.DataFrame(data, columns=['Value'])

    # 히스토그램 시각화
    plt.figure(figsize=(10, 6))
    sns.histplot(df['Value'], bins=30, kde=True, color='skyblue')  # bins: 막대 개수, kde: 커널 밀도 추정
    plt.title('Histogram of Values')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.show()

    # 박스 플롯 시각화
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df['Value'], color='lightgreen')
    plt.title('Box Plot of Values')
    plt.xlabel('Value')
    plt.show()


"""
(이차원 자료 및 시각화 기법)
- 이차원 자료란, 말 그대로 데이터의 특징이 2개로, 이차원 공간상에 나타낼 수 있는 자료를 의미합니다.
    앞으로는 단순한 2차원 자료보다는 N차원 자료들을 다루게 될 것인데,
    여기서 특별히 소개하는 이유는, 데이터 시각화에 가장 유리한 것이 2차원이며, 많아봐야 3차원 까지이기 때문에 소개하는 것입니다.

- 이차원 분할표(Contingency Table) :
    각 차원의 특성값의 도수 혹은 상대도수를 표에 나열한 것입니다.

- 산점도(Scatter Plot) :
    이차원 데이터를 나타내기 가장 알맞은 그래프로,
    2차원 좌표 공간 위에 데이터를 점으로 나타내는 것입니다.
"""


def two_dimensional_data_sample():
    # 데이터 생성
    np.random.seed(42)  # 재현성을 위해 시드 설정
    category1 = np.random.choice(['A', 'B', 'C'], size=1000)  # 'A', 'B', 'C' 범주 중 하나를 무작위로 선택
    category2 = np.random.choice(['X', 'Y', 'Z'], size=1000)  # 'X', 'Y', 'Z' 범주 중 하나를 무작위로 선택
    value1 = np.random.normal(loc=50, scale=15, size=1000)  # 연속형 변수 1
    value2 = np.random.normal(loc=30, scale=10, size=1000)  # 연속형 변수 2

    # 데이터프레임 생성
    df = pd.DataFrame({'Category1': category1, 'Category2': category2, 'Value1': value1, 'Value2': value2})

    # Contingency Table 생성
    contingency_table = pd.crosstab(df['Category1'], df['Category2'])
    print("Contingency Table:")
    print(contingency_table)

    # Contingency Table 시각화
    plt.figure(figsize=(10, 6))
    sns.heatmap(contingency_table, annot=True, fmt='d', cmap='YlGnBu')
    plt.title('Contingency Table Heatmap')
    plt.xlabel('Category2')
    plt.ylabel('Category1')
    plt.show()

    # Scatter Plot 시각화
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x='Value1', y='Value2', hue='Category1', style='Category2', data=df, palette='deep')
    plt.title('Scatter Plot of Value1 vs Value2')
    plt.xlabel('Value1')
    plt.ylabel('Value2')
    plt.legend(title='Categories')
    plt.show()


"""
(추정)
- 모집단의 특성값(모수)에 대한 추측값과 그 오차의 한계를 제시하는 것을 추정이라 합니다.

- 모수의 추정은 주로 점추정과 구간 추정을 함께 행합니다.


(불편추정량(Unbiased Estimator))
- 불편 추정량이란 말을 풀어쓰면 편향되지 않은 추정량이라는 의미입니다.
    모집단의 모든 데이터를 관측하기 어려운 경우에 샘플을 추출한다고 했는데,
    이 샘플은 무작위로 추출했을 경우 모집단의 확률분포에 따라 데이터가 추출될 것입니다.
    이 값들이 모집단의 형태를 대변하게 되는데, 모집단의 지역적인 데이터 분포에 편향되지 않고 모집단을 대표할 수 있는 추정량을 불편 추정량이라 부르며,
    결국 표본을 추출하여 행하는 통계는 불편 추정량을 얻기 위한 통계가 되는 것입니다.


(점 추정(Point Estimation))
- 모수의 추정에 사용되는 통계량인 추정량(Estimator)을 이용하여 표본이 주어지면 그에 따른 값을 제공하는 추정방식입니다.
    모집단에 대한 통계량을 구할 수 없으므로 표본의 통계량을 구하는 것으로 생각하면 되는데,
    모평균의 추정량은 표본 평균을,
    모분산의 추정량은 표본 분산을 사용하여 추정하는 것입니다.


(구간 추정(Interval Estimation))
- 추정량의 신뢰구간(Confidence Interval)을 제공하여 모수의 범위를 추측하는 것입니다.

- 신뢰구간의 형태는 모집단의 분포에 따라 다릅니다.
    정규모집단의 평균을 추정하는 경우, 추정하고자 하는 모평균에 대칭인 형태의 신뢰구간을 사용합니다.


(신뢰구간(Confidence Interval))
- 신뢰구간은 모집단의 모수(예를 들어 평균이나 비율)에 대한 추정치가 포함될 것으로 예상되는 구간을 나타냅니다. 
    구체적으로 말하면, 표본 데이터를 사용하여 계산한 추정치(예: 표본 평균) 를 중심으로 한 일정 거리의 구간을 의미합니다.

- 신뢰수준 (Confidence Level)
    신뢰구간은 주어진 데이터에서 계산된 추정치가 모집단의 실제 모수를 포함할 확률을 나타내는 신뢰수준으로 설명됩니다. 
    일반적으로 사용되는 신뢰수준은 90%, 95%, 99% 등이 있습니다. 
    예를 들어, 95% 신뢰수준의 신뢰구간은 통계적으로 100번 추출 시 95번은 실제 모수를 포함하고, 5번은 포함하지 않을 것으로 기대됩니다.

- 신뢰구간의 계산
    신뢰구간은 표본 통계량(예: 표본 평균)의 분포에 기초하여 계산됩니다. 
    일반적으로 표본 통계량의 분포는 중심극한정리에 따라 정규분포를 따르거나, 
    표본 크기가 작거나 모집단 분포가 정규분포를 따르지 않을 경우 t-분포를 사용합니다.

    가장 일반적으로 사용되는 경우는 표본 평균의 신뢰구간을 계산하는 것입니다. 
    예를 들어, n개의 표본을 추출하여 표본 평균 x`과 표본 표준편차s를 계산한 후, 
    정규분포 또는 t-분포를 이용하여 다음과 같이 계산할 수 있습니다:

    x` +- (z * s / sqrt(n))

    여기서 z는 표준 정규분포 또는 t-분포에서 얻은 특정 신뢰수준에 해당하는 값입니다.
    예를 들어, 95% 신뢰수준을 갖는 경우 표준 정규분포상에서 0.95 를 제외한 부분이 0.05이므로, 양쪽 꼬리 부분이 각각 0.025 씩 분포된 값을 찾아야 하는데,
    표준 정규분포의 누적 분포 함수 (CDF)에서 0.975에 해당하는 값을 찾으면 됩니다.

- 예시
    모집단에서 크기가 10000인 데이터가 있습니다.
    이 모집단은 평균이 50이고, 표준편차가 10인 정규분포를 따른다고 가정합니다.
    우리는 이 모집단에서 크기가 100인 표본을 추출하여, 이 표본에서의 평균에 대한 95% 신뢰구간을 계산하려고 합니다.

    표본 평균이 49.5 가 나왔다고 가정하며,
    표본 표준편차는 10.2 가 나왔다고 하겠습니다.
    위 식에 따라서,
    49.5 +- (z * 10.2 / sqrt(100))
    인데, z 값을 표준 정규분포의 누적 분포 함수 (CDF)에서 0.975에 해당하는 값을 찾으면 1.96(정확히는 1.959963984540054) 이므로
    49.5 +- (1.96 * 10.2 / 10)
    이 신뢰구간입니다.
"""


def confidence_interval_sample():
    # 모집단의 설정
    population_mean = 50
    population_std = 30
    population_size = 10000

    # 모집단 데이터 생성
    population_data = np.random.normal(population_mean, population_std, population_size)

    # 표본 크기와 신뢰수준 설정
    sample_size = 100
    confidence_level = 0.95

    # 표본 추출
    sample = np.random.choice(population_data, size=sample_size, replace=False)

    # 표본 평균과 표준편차 계산
    sample_mean = np.mean(sample)
    sample_std = np.std(sample, ddof=1)

    # 신뢰구간 계산
    confidence_interval = stats.t.interval(
        confidence_level,
        df=sample_size - 1,
        loc=sample_mean,
        scale=sample_std / np.sqrt(sample_size)
    )

    # 그래프 그리기
    plt.figure(figsize=(10, 6))

    # 모집단 분포 시각화
    sns.histplot(population_data, kde=True, color='gray', label='Population', alpha=0.3)

    # 표본 데이터 시각화
    sns.histplot(sample, kde=True, color='blue', label='Sample', alpha=0.3)

    # 신뢰구간 시각화
    plt.axvline(confidence_interval[0], color='red', linestyle='--', label='Confidence Interval')
    plt.axvline(confidence_interval[1], color='red', linestyle='--')

    # 표본 평균 시각화
    plt.axvline(sample_mean, color='blue', linestyle='-', label='Sample Mean')

    # 모집단 평균 시각화
    plt.axvline(population_mean, color='green', linestyle='-', label='Population Mean')

    # 그래프 제목과 레이블 설정
    plt.title(f'Sample Mean and {confidence_level * 100}% Confidence Interval')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.legend()

    # 그래프 표시
    plt.show()


"""
(통계적 가설검정(statistical hypothesis testing))
- 통계적 가설 검정은 통계학에서 데이터를 분석하여 특정 가설이 참인지 아닌지를 결정하는 과정을 말합니다. 
    특히, 표본 데이터를 사용하여 모집단에 대한 가설을 검정하는 데 사용됩니다.


(귀무가설(null hypothesis))
- 귀무가설은 기존의 이론이나 법칙을 부정하는 것으로 보이는 현상이 관측되었을 때,
    이 현상의 반증으로서의 강도를 검증함으로써 기존 이론이나 법칙을 부정하거나 개선할지를 결정하기 위해 세우는 가설입니다.
    귀무가설은 일반적으로 "효과가 없다", "차이가 없다" 또는 "영향이 없다" 등을 의미하며, 
    즉 기존의 이론이나 법칙이 실제 현상에 무의미하다는 주장입니다.


(대립가설 (Alternative Hypothesis))
- 귀무가설에 대립되는 가설로, 어떠한 이론이나 법칙이 현실적으로 유의미한 영향력을 나타낸다는 주장입니다.


(유의성 검정(Test of significance))
- 귀무가설에 대한 반증의 강도를 제공하는 과정을 유의성 검정이라고 합니다.
    쉽게 설명하자면 귀무 가설을 선택할 것인지 대립 가설을 선택할 것인지를 합리적인 계산을 통해 결정하는 과정인데,
    t 분포, F 분포, 카이제곱 분포 등의 검정 통계량과 허용 가능한 오류의 최대 확률을 뜻하는 유의 수준이 기준이 됩니다.


(단측(One-Side) 가설, 양측(Two-Side) 가설)
- 귀무 가설이 a = a` 이라고 할 때,
    대립 가설이 a >= a` 혹은 a <= a` 이런식으로 한 방향으로 제시되는 것을 단측 가설이라고 하며,
    a != a` 과 같이 양방향으로 제시되는 가설을 양측 가설이라고 합니다.


(가설 오류)
- 1 종 오류 : 귀무가설이 옳은 상황에서 귀무가설을 기각함으로 인해 생기는 오류를 제 1종 오류라고 합니다.

- 2 종 오류 : 귀무가설이 틀린 상황에서 귀무가설을 기각하지 못함으로 생기는 오류를 제 2종 오류라고 합니다.


(유의 확률(Significance Probability))
- 유의성 검정에서는 반증의 강도를 제 1종 오류가 일어날 확률 을 통해 제시합니다.
    반증의 강도가 높아질수록 제 1종 오류가 일어날 확률은 낮아지고, 이는 실제 관측된 결과보다 강력한 반증을 얻게 될 확률 역시 낮아짐을 의미합니다.
    이러한 확률을 유의 확률, 혹은 P-Value 라고 하고, 
    유의확률과 비교하여 대립가설의 유의성을 검정하게 될 기준값을 유의수준(Significance Level) 이라 합니다.

- 예를들어 유의 수준이 a = 0.05 라 함은, 관측 결과보다 더욱 귀무가설에 대한 반증이 강하게 나타날 수 있는 기회가 5% 이하라고 설정하는 것이 됩니다.
    조사를 진행한 결과, 유의 확률이 지정된 유의 수준 이하로 나타나면 조사 결과가 통계적으로 유의하다라고 표현할 수 있는 것입니다.


(기각역(Critical Region))
- 귀무가설을 기각시킬 수 있는 검정 통계량의 관측값 영역을 기각역이라고 합니다.
    유의 확률이 유의수준 이하로 나타나게 되는 영역이라고 볼 수 있습니다.


(유의성 검정의 절차)
1. 귀무가설, 대립가설, 유의수준을 설정

2. 표본을 추출하고 검정통계량 계산

3. 검정통계량의 값을 유의수준과 비교하여 평가합니다.
    이때, 유의확률이나 기각역을 통해 검정통계량의 값을 평가하고 귀무가설을 기각할 수 있는지 판단하게 됩니다.

4. 가설을 기각할 수 있는지 없는지를 판단하고, 결론을 이끌어냅니다.
"""

"""
(유의성 검정 실습)
- 가정 :
    A사에서 생산중인 고양이 사료 캔의 열량은 평균 1200kcal, 표준편차가 100kcal 로 알려져 있습니다.
    사료의 열량을 늘리기 위해 재료를 일부 변경하여 만든 시제품을 25개 생산하여 조사한 결과 평균 열량이 1240kcal 이었습니다.
    새로운 재료로 만든 사료 열량의 표준편차가 100kcal 로 유지된다고 할 때, 이 조사 결과는 사료의 열량을 늘리기 위한 재료 변경이 성공적임을 뜻하나요?

- 가설 설정 :
    귀무가설 = 사료 열량이 변함이 없이 평균 1200kcal 일 것이다
    대립가설 = 사료 열량이 증가하였으며, 평균 1200kcal 를 초과하였을 것이다.
    표준편차 = 동일하게 100kcal
    표본개수 = 25
    유의수준 설정 = 0.05

- 검정통계량 계산 :
    Z = (x` - mu0) / (a / sqrt(n))
    z = (1240-1200) / (100 / sqrt(25))
    z = 2.0

- 기각역 구하기 :
    유의수준이 0.05 인 경우, 단측 검정에서 기각역은 확률 분포의 상위 5%에 해당하는 값이 됩니다. 
    표준정규분포표를 참고하면 유의수준 0.05 일 때 임계값은 약 1.645 입니다.

    따라서, 
    기각역이 1.645를 초과하면 귀무가설을 기각할 수 있습니다.

- 유의확률(P-Value) 구하기 :
    유의 확률은 관측된 Z 값에 해당하는 누적분포함수 (CDF) 값을 이용하여 구합니다. 
    Z=2.0 인 경우, 표준정규분포에서의 누적분포함수 값을 찾으면 됩니다.

    표준정규분포표 또는 계산기를 이용하면
    유의 확률 (p-value) 은 약 0.0228 입니다.
"""


def parametric_significance_test():
    alpha = 0.05
    z_critical = stats.norm.ppf(1 - alpha)
    print(z_critical)

    # 주어진 값
    mu_0 = 1200  # 귀무가설의 평균
    x_bar = 1240  # 표본 평균
    sigma = 100  # 모집단 표준편차
    n = 25  # 표본 크기

    # 검정 통계량 계산
    z = (x_bar - mu_0) / (sigma / (n ** 0.5))

    # 유의확률 계산
    p_value = 1 - stats.norm.cdf(z)
    print(p_value)


"""
- 위에서 기각역은 1.6448536269514722, 유의확률은 0.02275013194817921 로 계산되므로,
    기각역을 통해 봤을 때는 2.0 이 이보다 크기에 귀무가설이 기각되며,
    유의 확률로 봤을 때도 p-value 가 0.0228 이므로 유의확률 0.5 보다 작으므로 재료 변경에 따른 열량의 증량에 유의미한 변화가 있으므로
    귀무 가설이 기각되는 것을 확인할 수 있습니다.
"""

"""
(표본을 통한 모평균에 대한 추론)
- 위에서 설명한 유의성 검증에서는 모평균과 모분산이 주어진 상황에서 정규분포를 통해
    p-value 및 기각역을 구했고, 이로써 통계적 추론을 할 수 있음을 다뤘습니다.
    이번에는 모집단에 대한 정보가 없이 표본만으로 추론을 진행하는 법을 알아볼 것입니다.

- 모평균에 대한 추론을 할 때에는 일반적으로 표본평균을 사용합니다.
    또한 모분산마저 알려지지 않은 경우에는 표본표준편차를 사용하여 정규분포가 아닌 t분포를 통하여 추론을 진행해 나가야 합니다.

- 모수를 사용하지 못하는 상황에서의 검정 통계량 계산은 표본의 통계값을 사용하면 됩니다.
    예를들어 모평균은 표본 평균으로, 모수 표준편차는 표본 표준편차로 대체하면 됩니다.
    이를 스튜던트화(Studentize) 라고 합니다.
    이렇게 스튜던트화한 검정 통계량을 t-검정 통계량이라고 합니다.

- 실습해봅시다.
    가정 :
        전구를 생산하는 한 회사에서 현재 생산하는 전구의 평균수명은 1950 시간으로 알려져 있습니다.
        개발중인 전구의 평균수명 mu 가 기존 전구보다 수명이 더 길다고 할 수 있는지 판단하기 위해 9개의 시제품을 생산하여 그 수명시간을 조사한 결과는,
        (2000, 1975, 1900, 2000, 1950, 1850, 1950, 2100, 1975)
        이와 같습니다.

    정리 :
        위에서 우리가 알 수 있는 모수의 평균은 1950 입니다.
        가설을 설정해보자면 귀무가설은 mu 가 1950 과 차이가 없다는 것이고, 대립가설은 mu 가 1950 보다 크다는 것입니다.
        표본의 수는 9개인데, 유의 수준을 0.05 라고 했을 때,
        유의 확률을 구하고 가설검증을 해봅시다.
"""


def sample_significance_test():
    # 주어진 데이터
    data = np.array([2000, 1975, 1900, 2000, 1950, 1850, 1950, 2100, 1975])

    # 표본 평균과 표본 표준편차 계산
    sample_mean = np.mean(data)
    sample_std = np.std(data, ddof=1)  # 표본 표준편차이므로 자유도 1

    # 가설 검정에 필요한 값들
    mu_0 = 1950  # 귀무가설의 평균
    n = len(data)  # 표본 크기

    # t-검정 통계량 계산
    t_stat = (sample_mean - mu_0) / (sample_std / np.sqrt(n))

    # 유의 확률(p-value) 계산
    p_value = 1 - stats.t.cdf(t_stat, df=n - 1)

    # 결과 출력
    print("표본 평균:", sample_mean)
    print("표본 표준편차:", sample_std)
    print("t-검정 통계량:", t_stat)
    print("유의 확률(p-value):", p_value)

    # 유의 수준
    alpha = 0.05

    if p_value < alpha:
        print("귀무가설을 기각합니다. 개발 중인 전구의 평균 수명이 기존 전구보다 유의미하게 깁니다.")
    else:
        print("귀무가설을 기각하지 않습니다. 개발 중인 전구의 평균 수명이 기존 전구보다 유의미하게 길지 않습니다.")


def main():
    # discrete_data_sample()
    # continuous_data_sample()
    # two_dimensional_data_sample()
    # confidence_interval_sample()
    # parametric_significance_test()
    sample_significance_test()


if __name__ == '__main__':
    main()
